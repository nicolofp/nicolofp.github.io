[
  {
    "objectID": "projects/gps/gps_analysis_nlme.html",
    "href": "projects/gps/gps_analysis_nlme.html",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#introduction",
    "href": "projects/gps/gps_analysis_nlme.html#introduction",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "href": "projects/gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "title": "Heart rate recovery analysis",
    "section": "2 Experiment and data collection",
    "text": "2 Experiment and data collection\nHeart rate data were collected (on a single individual over months of training sessions) using a wearable heart rate watch immediately following a 30-minute running session on a treadmill. The standardized workout comprised three phases: the first 15 minutes at 6.5 miles per hour, the next 10 minutes at 7.0 miles per hour, and the final 5 minutes at 7.5 miles per hour. Data collection began at the instant the 30-minute workout concluded (time t=0) and continued for the subsequent 5 to 20 minutes post-exercise, capturing the heart rate recovery phase. The wearable watch, equipped with an optical heart rate sensor, was configured to record heart rate data at a 5-second granularity, yielding 12 measurements per minute (60 seconds ÷ 5 seconds). Over the 15-minute recovery window (from 5 to 20 minutes, or 900 seconds), this resulted in 180 data points (900 seconds ÷ 5 seconds). The watch was securely worn on the wrist to ensure accurate and consistent measurements, with data stored locally on the device and later exported for analysis. Timestamps were aligned to the end of the workout to precisely track the heart rate decrease during the recovery period, enabling detailed analysis of cardiovascular recovery dynamics following the standardized treadmill session.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#statistical-model",
    "href": "projects/gps/gps_analysis_nlme.html#statistical-model",
    "title": "Heart rate recovery analysis",
    "section": "3 Statistical model",
    "text": "3 Statistical model\nTo model the heart rate decrease during the recovery phase following a 30-minute standardized treadmill running session, we adopted a non-linear mixed effects (NLME) model, informed by peer-reviewed literature on heart rate recovery dynamics (See [1], [2], [3], [4], [5]). The recovery phase, spanning from 0 to 20 minutes post-exercise with heart rate data collected at 5-second intervals, exhibits a non-linear decay pattern, as heart rate typically decreases rapidly initially and then stabilizes over time. This non-linear behavior, combined with inter-session variability (e.g., due to fitness levels or training frequency) and the hierarchical nature of the data (repeated measurements within sessions), makes an NLME model suitable. Peer-reviewed studies, such as those in exercise physiology, highlight NLME models as effective for capturing both individual-level trends and session-specific variations in heart rate recovery, accounting for factors like the number of training sessions in the past two weeks.\nThe NLME model can be expressed as follows:\n\\[y_{ij} = f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i) + \\epsilon_{ij}\\]\nwhere:\n\n\\(y_{ij}\\): Heart rate measurement for individual \\(i\\) at time point \\(j\\),\n\\(f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i)\\): Non-linear function describing the heart rate recovery trajectory, dependent on time \\(x_{ij}\\), fixed effect parameters \\(\\boldsymbol{\\beta}\\), and individual-specific random effects \\(\\boldsymbol{b}_i\\),\n\\(\\boldsymbol{b}_i \\sim N(0, \\boldsymbol{\\Psi})\\): Random effects vector, assumed to follow a multivariate normal distribution with covariance matrix \\(\\boldsymbol{\\Psi}\\),\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): Residual error, assumed to be normally distributed with variance \\(\\sigma^2\\).\n\nThe negative exponential shape function was chosen because heart rate recovery typically exhibits a rapid initial decline followed by a slower stabilization, a pattern well-captured by this form. Peer-reviewed studies in exercise physiology support its use, as it effectively models the physiological process of cardiovascular recovery. Additionally, its parameters allow interpretable insights into amplitude, decay rate, and asymptotic heart rate, aligning with the data’s non-linear dynamics. The model for heart rate recovery is specified as: \\[y_{ij} = a_i \\cdot \\exp(-b_i \\cdot t_{ij}) + k + \\epsilon_{ij}\\] where:\n\n\\(y_{ij}\\): heart rate measurement for session \\(i\\) at time point \\(j\\)\n\\(t_{ij}\\): time since the end of the workout for session \\(i\\) at measurement \\(j\\)\n\\(a_i = \\alpha_0 + \\alpha_1 \\cdot \\text{training}_i + u_i\\): amplitude parameter for session \\(i\\), with \\(\\alpha_0\\) as the fixed intercept, \\(\\alpha_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(u_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(b_i = \\beta_0 + \\beta_1 \\cdot \\text{training}_i + v_i\\): decay rate parameter for session \\(i\\), with \\(\\beta_0\\) as the fixed intercept and \\(\\beta_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(v_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(k\\): Asymptotic heart rate, assumed constant across sessions,\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): residual error, assumed normally distributed with variance \\(\\sigma^2\\)\n\nThis model captures the non-linear heart rate recovery trajectory, incorporating the effect of training frequency as a fixed effect and session-specific variability through a random intercept.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#r-code",
    "href": "projects/gps/gps_analysis_nlme.html#r-code",
    "title": "Heart rate recovery analysis",
    "section": "4 R code",
    "text": "4 R code\nTo analyze the heart rate recovery data and model the non-linear decrease following the standardized treadmill workout, we will utilize the R programming environment in conjunction with the brms package, which interfaces with Stan for Bayesian statistical modeling. This approach enables robust fitting of the non-linear mixed effects model, leveraging Stan’s powerful Markov Chain Monte Carlo (MCMC) sampling to estimate model parameters while accounting for both fixed and random effects. The brms package provides a user-friendly framework to specify complex models, incorporate covariates such as the number of training sessions in the past two weeks, and handle the hierarchical structure of the data efficiently. See [6].\nWe load useful R libraries to handle data and bayesian model:\n\nlibrary(data.table)\nlibrary(gridExtra)\nlibrary(bayesplot)\nlibrary(cmdstanr)\nlibrary(ggplot2)\nlibrary(arrow)\nlibrary(brms)\n\nWe visualize the experimental data that are used for the statistical model\n\ndt_test = read_parquet(\"dataset.parquet\")\nt1 = ggplot(dt_test) +\n  geom_line(aes(x = time, y = hr, group = date), alpha = 0.3) +\n  geom_smooth(aes(x = time, y = hr)) +\n  labs(title = \"Experimental data\") + \n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\nt2 = ggplot(dt_test) +\n  geom_boxplot(aes(x = as.factor(time), y = hr), fill = \"#69b3a2\",alpha = 0.3) +\n  labs(title = \"Experimental data\") + \n  scale_x_discrete(breaks = seq(0,15)) +\n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\ngrid.arrange(t1,t2,ncol = 2)\n\n\n\n\n\n\n\n\nIn this block we have the code for the bayesian no-linear mixed effect model. We leverage STAN bayesian framework through brms package. The coefficient \\(b\\) need to be positive (in order to have \\(-b\\) always negative) but the intercept and coefficient of \\(\\text{training}_i\\) can be positive or negative, for this reason we estimate the \\(log(b)\\) and then we exponentiate the variable logb to get our final results. We select priors and the initial points based on literature and data observations.\n\nfit_exponential &lt;- brms::brm(\n  formula = brms::bf(hr ~ a * exp(-exp(logb) * time) + k, \n                     a + logb ~ 1 + N_train + (1 | date),\n                     k ~ 1,\n                     nl=TRUE),\n  data = dt_test,\n  cores = 4,\n  backend = \"cmdstan\",\n  init = replicate(4,list(b_a_Intercept = 95       # Fixed intercept for a\n                          ,b_a_N_train = 0         # Effect of N_train on a\n                          ,b_b_Intercept = 0\n                          ,b_b_N_train = 0\n                          ,b_k_Intercept = 90\n                          ), \n                   simplify = F),\n  seed = 85538,\n  prior   = c(prior(normal(96,1), nlpar = \"a\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"a\", coef=\"N_train\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"N_train\"),\n              prior(normal(90,1), nlpar = \"k\", lb = 0)),\n  control = list(adapt_delta = 0.99,\n                 max_treedepth = 15),\n  file = \"nlme_gps/fit_exp_re_cov.rds\"\n)\n\nLet’s see the results of the analysis\n\nfit_exponential\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: hr ~ a * exp(-exp(logb) * time) + k \n         a ~ 1 + N_train + (1 | date)\n         logb ~ 1 + N_train + (1 | date)\n         k ~ 1\n   Data: dt_test (Number of observations: 1937) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~date (Number of levels: 74) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(a_Intercept)        6.27      0.99     4.46     8.38 1.00     1382     2197\nsd(logb_Intercept)     0.27      0.03     0.22     0.32 1.00      942     1796\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\na_Intercept       94.25      0.86    92.55    96.00 1.00     2606     2484\na_N_train         -1.09      0.31    -1.70    -0.51 1.00     2316     2437\nlogb_Intercept    -0.95      0.06    -1.06    -0.84 1.01      842     1547\nlogb_N_train      -0.01      0.02    -0.04     0.02 1.00      641     1592\nk_Intercept       92.74      0.32    92.11    93.34 1.00     8288     2942\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.26      0.12     7.03     7.50 1.00     5952     2999\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe model implemented demonstrates robust convergence with all Rhat values at or very close to 1.0. The model characterizes an exponential decay function with a Gaussian distribution, revealing a baseline parameter estimate of 94.25 (95% CI: 92.55-96.00) that exhibits a significant negative effect (-1.09, 95% CI: -1.70 to -0.51) proportional to the number pf training in the previous 14 days. The log decay rate is estimated at -0.95 (95% CI: -1.06 to -0.84), with minimal influence from training in the previous 14 days(-0.01, 95% CI: -0.04 to 0.02). The response asymptotes (not a mathematical one but it’s the value where the heart rate decrease slow down) at approximately 92.74 (95% CI: 92.11-93.34). Notable random effects include substantial between-date variability in the baseline parameter (SD=6.27) and moderate variability in decay rate (SD=0.27), while the residual standard deviation is 7.26 (95% CI: 7.03-7.50). All parameters demonstrate adequate effective sample sizes for reliable estimation.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#references",
    "href": "projects/gps/gps_analysis_nlme.html#references",
    "title": "Heart rate recovery analysis",
    "section": "5 References",
    "text": "5 References\n\n\n[1] G. L. Pierpont, S. Adabag, and D. Yannopoulos, “Pathophysiology of exercise heart rate recovery: A comprehensive analysis,” Annals of Noninvasive Electrocardiology, vol. 18, no. 2, pp. 107–117, 2013, doi: https://doi.org/10.1111/anec.12061.\n\n\n[2] C. R. Cole, E. H. Blackstone, F. J. Pashkow, C. E. Snader, and M. S. Lauer, “Heart-rate recovery immediately after exercise as a predictor of mortality,” New England Journal of Medicine, vol. 341, no. 18, pp. 1351–1357, 1999, doi: 10.1056/NEJM199910283411804.\n\n\n[3] H. A. M. Daanen, R. P. Lamberts, V. L. Kallen, A. Jin, and N. L. U. V. Meeteren, “A systematic review on heart-rate recovery to monitor changes in training status in athletes,” International Journal of Sports Physiology and Performance, vol. 7, no. 3, pp. 251–260, 2012, doi: 10.1123/ijspp.7.3.251.\n\n\n[4] T. P. Facioli et al., “Study of heart rate recovery and cardiovascular autonomic modulation in healthy participants after submaximal exercise,” Scientific Reports, vol. 11, no. 1, p. 3620, Feb. 2021, doi: 10.1038/s41598-021-83071-w.\n\n\n[5] R. X. da Fonseca, C. J. Gomes da Cruz, E. de M. K. V. K. Soares, G. L. Garcia, L. G. G. Porto, and G. E. Molina, “Post-exercise heart rate recovery and its speed are associated with resting-reactivity cardiovagal modulation in healthy women,” Scientific Reports, vol. 14, no. 1, p. 5526, Mar. 2024, doi: 10.1038/s41598-024-51842-w.\n\n\n[6] M. Franke, “Bayesian Regression: Theory &amp; Practice - Non-linear models in brms — michael-franke.github.io.” https://michael-franke.github.io/Bayesian-Regression/practice-sheets/10a-nonLinear.html.",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#appendix",
    "href": "projects/gps/gps_analysis_nlme.html#appendix",
    "title": "Heart rate recovery analysis",
    "section": "6 Appendix",
    "text": "6 Appendix\nAutocorrelation\n\nparameters = c(\"b_a_Intercept\",\"b_a_N_train\",\"b_logb_Intercept\",\n               \"b_logb_N_train\",\"b_k_Intercept\",\"sd_date__a_Intercept\",\n               \"sd_date__logb_Intercept\",\"sigma\")\nmcmc_acf(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nPosterior density\n\nmcmc_dens(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nTraceplot after warmup\n\nmcmc_trace(fit_exponential, pars = parameters)",
    "crumbs": [
      "Layout",
      "Sales Analysis"
    ]
  },
  {
    "objectID": "add_resume.html",
    "href": "add_resume.html",
    "title": "List of publications",
    "section": "",
    "text": "I am a quantitative data scientist with 8 years of comprehensive experience spanning pharmaceutical research, environmental health sciences, and financial markets across the United States and Italy. Currently, I work as a Quantitative Medicine Scientist at Critical Path Institute, where I develop disease progression models using linear and non-linear mixed effects frameworks in R and Stan, applying both frequentist and Bayesian approaches to analyze longitudinal Alzheimer’s data and identify predictive biomarkers. I have engineered automated ETL pipelines to transform clinical trial data from SDTM/ADaM standards into analysis-ready datamarts with robust data quality validation procedures.\nDuring my role as Biostatistician at the Icahn School of Medicine at Mount Sinai, I specialized in multi-omics data analysis, working with metabolomics and epigenetic datasets using machine learning techniques, dimensionality reduction methods like PCA, and t-SNE, and mixed-effects models for biomarker identification and biological pathway validation. I developed a novel Bayesian mixture regression R package using Stan and applied time series models including Distributed Lag Models, ARIMA, Bayesian splines, and Gaussian State Space Models for environmental health research. My work involved implementing machine learning pipelines with XGBoost, tree-based models, and polynomial regression for biomarkers prediction on large-scale genomic data, while building automated ETL workflows and generating publication-ready reports that contributed to peer-reviewed publications ([1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]).\nMy financial sector experience includes roles as a Quantitative Analyst at InchCapital and Data Scientist at Gala S.p.A. in Milan, where I executed time series analysis using ARIMA and Hidden Markov Models to detect trading patterns and design quantitative strategies across multi-asset portfolios. I optimized investment portfolios using Markowitz theory and advanced methodologies to maximize risk-adjusted returns, while building mathematical models for commodity price forecasting and deploying parallel processing solutions on Linux servers. Throughout my career, I have maintained expertise in R, Stan, Julia, and SQL, consistently delivering automated analytical solutions that bridge complex statistical theory with practical business applications.",
    "crumbs": [
      "Layout",
      "List of publications"
    ]
  },
  {
    "objectID": "add_resume.html#introduction",
    "href": "add_resume.html#introduction",
    "title": "List of publications",
    "section": "",
    "text": "I am a quantitative data scientist with 8 years of comprehensive experience spanning pharmaceutical research, environmental health sciences, and financial markets across the United States and Italy. Currently, I work as a Quantitative Medicine Scientist at Critical Path Institute, where I develop disease progression models using linear and non-linear mixed effects frameworks in R and Stan, applying both frequentist and Bayesian approaches to analyze longitudinal Alzheimer’s data and identify predictive biomarkers. I have engineered automated ETL pipelines to transform clinical trial data from SDTM/ADaM standards into analysis-ready datamarts with robust data quality validation procedures.\nDuring my role as Biostatistician at the Icahn School of Medicine at Mount Sinai, I specialized in multi-omics data analysis, working with metabolomics and epigenetic datasets using machine learning techniques, dimensionality reduction methods like PCA, and t-SNE, and mixed-effects models for biomarker identification and biological pathway validation. I developed a novel Bayesian mixture regression R package using Stan and applied time series models including Distributed Lag Models, ARIMA, Bayesian splines, and Gaussian State Space Models for environmental health research. My work involved implementing machine learning pipelines with XGBoost, tree-based models, and polynomial regression for biomarkers prediction on large-scale genomic data, while building automated ETL workflows and generating publication-ready reports that contributed to peer-reviewed publications ([1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]).\nMy financial sector experience includes roles as a Quantitative Analyst at InchCapital and Data Scientist at Gala S.p.A. in Milan, where I executed time series analysis using ARIMA and Hidden Markov Models to detect trading patterns and design quantitative strategies across multi-asset portfolios. I optimized investment portfolios using Markowitz theory and advanced methodologies to maximize risk-adjusted returns, while building mathematical models for commodity price forecasting and deploying parallel processing solutions on Linux servers. Throughout my career, I have maintained expertise in R, Stan, Julia, and SQL, consistently delivering automated analytical solutions that bridge complex statistical theory with practical business applications.",
    "crumbs": [
      "Layout",
      "List of publications"
    ]
  },
  {
    "objectID": "add_resume.html#list-of-publications",
    "href": "add_resume.html#list-of-publications",
    "title": "List of publications",
    "section": "List of publications",
    "text": "List of publications\n\n\n[1] E. Colicino, N. F. Pedretti, S. A. Busgang, and C. Gennings, “Per- and poly-fluoroalkyl substances and bone mineral density: Results from the bayesian weighted quantile sum regression,” Environmental Epidemiology, vol. 4, no. 3, 2020, [Online]. Available: https://journals.lww.com/environepidem/fulltext/2020/06000/per__and_poly_fluoroalkyl_substances_and_bone.3.aspx.\n\n\n[2] E. Colicino et al., “Prenatal exposure to multiple organochlorine compounds and childhood body mass index,” Environmental Epidemiology, vol. 6, no. 3, 2022, [Online]. Available: https://journals.lww.com/environepidem/fulltext/2022/06000/prenatal_exposure_to_multiple_organochlorine.2.aspx.\n\n\n[3] E. Colicino et al., “Cross-cohort mixture analysis: A data integration approach with applications on gestational age and DNA-methylation-derived gestational age acceleration metrics,” medRxiv, 2023, doi: 10.1101/2023.04.14.23288581.\n\n\n[4] H. M. Thompson et al., “The development of frailty trajectories in world trade center general responders and the association with world trade center exposure,” The Journal of Frailty & Aging, vol. 14, no. 2, p. 100027, 2025, doi: https://doi.org/10.1016/j.tjfa.2025.100027.\n\n\n[5] M. J. Rosa et al., “Integrating data across multiple sites in the northeastern united states to examine associations between a prenatal metal mixture and child cognition,” American Journal of Epidemiology, vol. 193, no. 4, pp. 606–616, Nov. 2023, doi: 10.1093/aje/kwad233.\n\n\n[6] C. S. Alcala et al., “Prenatal exposure to phthalates and childhood wheeze and asthma in the PROGRESS cohort,” Science of The Total Environment, vol. 954, p. 176311, 2024, doi: https://doi.org/10.1016/j.scitotenv.2024.176311.\n\n\n[7] D. Carrión et al., “Neighborhood-level disparities and subway utilization during the COVID-19 pandemic in new york city,” Nature Communications, vol. 12, no. 1, p. 3692, Jun. 2021, doi: 10.1038/s41467-021-24088-7.\n\n\n[8] E. Colicino et al., “Maternal steroids during pregnancy and their associations with ambient air pollution and temperature during preconception and early gestational periods,” Environment International, vol. 165, p. 107320, 2022, doi: https://doi.org/10.1016/j.envint.2022.107320.\n\n\n[9] L. Gerbi et al., “Biomarkers of maternal lead exposure during pregnancy using micro-spatial child deciduous dentine measurements,” Environment International, vol. 169, p. 107529, 2022, doi: https://doi.org/10.1016/j.envint.2022.107529.\n\n\n[10] E. Colicino et al., “Prenatal urinary concentrations of phthalate metabolites and behavioral problems in mexican children: The programming research in obesity, growth environment and social stress (PROGRESS) study,” Environmental Research, vol. 201, p. 111338, 2021, doi: https://doi.org/10.1016/j.envres.2021.111338.\n\n\n[11] E. Colicino et al., “Non-linear and non-additive associations between the pregnancy metabolome and birthweight,” Environment International, vol. 156, p. 106750, 2021, doi: https://doi.org/10.1016/j.envint.2021.106750.\n\n\n[12] E. Colicino et al., “Association between prenatal immune phenotyping and cord blood leukocyte telomere length in the PRISM pregnancy cohort,” Environmental Research, vol. 191, p. 110113, 2020, doi: https://doi.org/10.1016/j.envres.2020.110113.",
    "crumbs": [
      "Layout",
      "List of publications"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Basics",
      "About"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "test_project_quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Introduction"
    ]
  }
]