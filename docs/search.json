[
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html",
    "title": "Solar energy forecast",
    "section": "",
    "text": "Import libraries for data cleaning, statistics, machine learning and visualization\n\nusing Dates, DataFrames, Plots, StatsPlots, Statistics, Distributions\nusing StatsBase, HypothesisTests, LinearAlgebra, Random, MLJ, CSV, CategoricalArrays",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html#import-libraries",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html#import-libraries",
    "title": "Solar energy forecast",
    "section": "",
    "text": "Import libraries for data cleaning, statistics, machine learning and visualization\n\nusing Dates, DataFrames, Plots, StatsPlots, Statistics, Distributions\nusing StatsBase, HypothesisTests, LinearAlgebra, Random, MLJ, CSV, CategoricalArrays",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html#dataset",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html#dataset",
    "title": "Solar energy forecast",
    "section": "2 Dataset",
    "text": "2 Dataset\nOur data contains information on these key factors:\n\ntimedate: date and hour of each datapoint\nWindSpeed: wind speed in Km/h\nSunshine: minutes per hours that sun is not cover by clouds (scaled 0-60)\nAirPressure: athmosphere pressure in hPa\nRadiation: solar radiation W/m2\nAirTemperature: air temperature in Celsius\nRelativeAirHumidity: relative humidity (scaled 0-100)\nSystemProduction: system production kWh\n\n\nDT = CSV.read(\"Solar_Power_Plant_Data.csv\", DataFrame);\nshow(describe(DT),allcols = true)\n\n\n8×7 DataFrame\n\n Row │ variable             mean     min               median  max               nmissing  eltype   \n\n     │ Symbol               Union…   Any               Union…  Any               Int64     DataType \n\n─────┼──────────────────────────────────────────────────────────────────────────────────────────────\n\n   1 │ Date-Hour(NMT)                01.01.2017-00:00          31.12.2017-23:00         0  String31\n\n   2 │ WindSpeed            2.63982  0.0               2.3     10.9                     0  Float64\n\n   3 │ Sunshine             11.1805  0                 0.0     60                       0  Int64\n\n   4 │ AirPressure          1010.36  965.9             1011.0  1047.3                   0  Float64\n\n   5 │ Radiation            97.5385  -9.3              -1.4    899.7                    0  Float64\n\n   6 │ AirTemperature       6.97889  -12.4             6.4     27.1                     0  Float64\n\n   7 │ RelativeAirHumidity  76.7194  13                82.0    100                      0  Int64\n\n   8 │ SystemProduction     684.746  0.0               0.0     7701.0                   0  Float64\n\n\n\nIn the table above we don’t have any real missing data but we can see some problematic values (like the negative values for solar radiation). We assume that each negative value of solar radiation is due to some data trasmission error so we set all the negative value equal to zero, in addition we parse the data related to the hour and date to timedate format\n\nDT[DT.Radiation .&lt; 0,:Radiation] .= 0.0;\n\nDT.day = parse.(Int64,chop.(DT[:,\"Date-Hour(NMT)\"], head = 0, tail = 14))\nDT.month = parse.(Int64,chop.(DT[:,\"Date-Hour(NMT)\"], head = 3, tail = 11))\nDT.hour = parse.(Int64,chop.(DT[:,\"Date-Hour(NMT)\"], head = 11, tail = 3));\n\nrename!(DT,\"Date-Hour(NMT)\" =&gt; \"timedate\");\n\n# Create column with right formatting\nDT.timedate_real = DateTime.(2017,DT.month,DT.day,DT.hour);\nDT.date_real = Date.(2017,DT.month,DT.day);\n\nLet’s visualize the SystemProduction for each hour:\n\nplot(DT.timedate_real, DT.SystemProduction, \n    title=\"Hourly production\", label= :none, size=(750,300))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plot we notice that we have some multiple consecutive days where the production is zero (for example in Jan, May, Dec). It seems that instead of missing value we have some zero value when we don’t have available data. We need to be very careful while performing the data cleaning because during the night the actual production of the solar panel is zero. Let’s group by day and check the days with zero production\n\ndf = groupby(DT, :date_real)\ndt = combine(df, \n             [\"SystemProduction\",\"WindSpeed\",\n             \"Sunshine\",\"AirPressure\",\n              \"Radiation\",\"AirTemperature\",\n              \"RelativeAirHumidity\",\"month\"] .=&gt; [sum, mean, mean, \n                                                  mean, mean, mean, \n                                                  mean, mean]; \n    renamecols = true);\nsort!(dt,:date_real);\n\np1 = scatter(dt.Radiation_mean, dt.SystemProduction_sum, title = \"Production vs Radiation (day)\", \n             label= :none)\np1 = vline!([40], label= :none)\np1 = hline!([1800], label= :none)\np2 = scatter(DT.Radiation, DT.SystemProduction, title = \"Production vs Radiation (hour)\", \n             label= :none)\n\nplot(p1, p2, layout=(1,2), size=(750,300))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plot is clear that we have some outlier where radiation is grater than 40 W/m2 and production is lower than 1800 kWh per day. Let’s mark those days as suspicious and check if we have hour that can have some suspiciuos data, then compute the correlation between variables in the clean dataset\n\nsuspect_day = dt[(dt.Radiation_mean .&gt; 40) .&& (dt.SystemProduction_sum .&lt; 1800),:date_real]\nfilter!([:date_real, :SystemProduction, :Radiation] =&gt; (x,y,z) -&gt; x ∉ Ref(suspect_day) && \n        !(y == 0 && z &gt; 40), DT)\ncor(Matrix(DT[:,2:8]))\n\n7×7 Matrix{Float64}:\n  1.0         0.133932   -0.0432693  …   0.198341   -0.337062    0.205243\n  0.133932    1.0         0.0254894      0.392487   -0.605845    0.656582\n -0.0432693   0.0254894   1.0           -0.0323885  -0.0825695   0.0125299\n  0.189951    0.798208    0.0211536      0.535135   -0.616523    0.861283\n  0.198341    0.392487   -0.0323885      1.0        -0.384636    0.503138\n -0.337062   -0.605845   -0.0825695  …  -0.384636    1.0        -0.593409\n  0.205243    0.656582    0.0125299      0.503138   -0.593409    1.0\n\n\nLast step before the machine learning model is to include the time into a numerical variable using Cyclical Encoder. This methods allow us to take into account the time cyclicity for months, days, hours:\n\\[s(t) = \\sum_{n=1}^{N} \\left( a_n \\cos\\left(\\frac{2\\pi n t}{P}\\right) + b_n \\sin\\left(\\frac{2\\pi n t}{P}\\right) \\right)\\]\nWith the following code:\n\nfunction cyclical_encoder(df::DataFrame, columns::Union{Array, Symbol}, max_val::Union{Array, Int} )\n    for (column, max) in zip(columns, max_val)        \n        df[:, Symbol(string(column) * \"_sin\")] = sin.(2*pi*df[:, column]/max)\n        df[:, Symbol(string(column) * \"_cos\")] = cos.(2*pi*df[:, column]/max)\n    end\n    return df\nend\n\ncyclical_encoder(DT, [\"day\",\"month\",\"hour\"], [31,12,23]);",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html#machine-learning",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html#machine-learning",
    "title": "Solar energy forecast",
    "section": "3 Machine Learning",
    "text": "3 Machine Learning\nEvoTrees is a regression algorithm in Julia library for creating gradient boosting regression models. It allows you to build decision trees efficiently, focusing on performance. EvoTrees works by combining multiple weaker decision trees into a stronger final model. It supports various loss functions specifically designed for regression tasks, which guide the training process and evaluate how well your model performs. The library utilizes histogram-based algorithms for faster data processing and can also handle different types of features within your data, including categorical ones. Overall, EvoTrees provides a versatile toolkit for building regression models in Julia using gradient boosting.\nSplit the dataset in train and test considering only the hours with solar radiation grater than zero (exclude nights and evenings). We consider train from 01/01 to 06/30 and test from 07/01 to 12/31. We perform hourly estimation and then we group by day of the year. We include all the available variable into the model:\n\nDT_model = DT[DT.Radiation .&gt; 0.0,:]\ntrain, test = (collect(1:1828),collect(1829:3744));\nX = DT_model[:,vcat(2:7,14:19)];\ny = DT_model[:,:SystemProduction];\n\nWe need to load the EvoTreeRegressor algorithm, set the parameters, create the machine and cross validate the model using 5-folds repeating the operation for 5 times\n\nEvoTreeRegressor = MLJ.@load EvoTreeRegressor pkg=EvoTrees verbosity=0;\net_regressor = EvoTreeRegressor(nbins = 32, max_depth = 10, nrounds = 200);\n\nmodel_glm = et_regressor;\nmach_glm = machine(model_glm, X[train,:], y[train]);\nfit!(mach_glm, verbosity=0);\n\n# Cross-validation\nevaluate!(mach_glm, resampling = CV(nfolds=5, rng=1234), \n          repeats=5, measure = [rmse, rsquared], verbosity=0);",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html#results",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html#results",
    "title": "Solar energy forecast",
    "section": "4 Results",
    "text": "4 Results\n\nDT_model.predicts = zeros(size(DT_model,1))        \nDT_model[test,:predicts] .= MLJ.predict(mach_glm, X[test,:]);\n\ndf = groupby(DT_model, :date_real)\ndt = combine(df, [\"SystemProduction\",\"predicts\"] .=&gt; [sum, sum]; renamecols = true);\nsort!(dt,:date_real);\ndt = dt[dt.date_real .&gt; Date.(2017,6,30),:]\n\nq2 = plot(dt[:,:date_real],dt[:,:SystemProduction_sum],  title = \"Actual vs Predict\", label = \"Actual\")\nq2 = plot!(dt[:,:date_real],dt[:,:predicts_sum], mc = :orange, label = \"Predict\")\nq1 = scatter(dt[:,:SystemProduction_sum],dt[:,:predicts_sum], title = \"Actual vs Predict\", label = :none)\nq1 = plot!(collect(0:59000),collect(0:59000), label = :none, mc = :red)\n\nplot(q1, q2, layout=(1,2), size=(750,300))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprintln(\"RMSE: \", string.(rmse(dt[:,:SystemProduction_sum],dt[:,:predicts_sum])))\nprintln(\"MAE: \", string.(mae(dt[:,:SystemProduction_sum],dt[:,:predicts_sum])))\nprintln(\"R²: \", string.(cor(dt[:,:SystemProduction_sum],dt[:,:predicts_sum]).^2))\n\nRMSE: 4001.6449123866632\nMAE: 2863.85133695596\nR²: 0.9479576782299722",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/solar_forecast/solar_forecast_new.html#references",
    "href": "projects/portfolio/solar_forecast/solar_forecast_new.html#references",
    "title": "Solar energy forecast",
    "section": "5 References",
    "text": "5 References",
    "crumbs": [
      "Projects",
      "Solar energy forecast"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_mc_simulation.html",
    "href": "projects/portfolio/salmon/salmon_mc_simulation.html",
    "title": "Nicol&oacute; Foppa Pedretti",
    "section": "",
    "text": "using Statistics, Distributions, LinearAlgebra, Random, Plots\n\n\n#n_seed = 1990\nT = 50\nmu = 0.0003\nN_t0 = 1000\nW_max = 12.0\ngr = 0.025\nTw = 5.0\nmW_t0 = 2.0 \nsdW_t0 = 0.5;\n\n\nfunction farm_salmon_sim(N_t0, T, mu, mW_t0, sdW_t0, W_max, gr, Tw)\n    D_weight = Normal(mW_t0, sdW_t0)\n    M_rate = Bernoulli(mu)\n    W_t0 = rand(D_weight,N_t0)\n    W = hcat(W_t0,zeros(N_t0,T))\n    H = zeros(N_t0,T+1)\n    \n    for i in 2:(T+1)\n        mu = max(0.0,mu + rand(Normal(0.0,0.0001)))\n        gr = max(0.0,gr .+ rand(Normal(0.0,0.005)))\n        d_rate = ifelse.(W[:,i-1] .!= 0, abs.(rand(M_rate,N_t0) .-1),0.0) \n        g_rate = (1.0 .+ gr .* (1.0 .- W[:,i-1] ./ W_max)) \n        W[:,i] = g_rate .* W[:,i-1] .* d_rate\n        h_rate = ifelse.(W[:,i] .&gt;= Tw, 0, 1)\n        H[:,i] = W[:,i] .* abs.(h_rate .- 1)\n        W[:,i] = W[:,i] .* h_rate\n    end\n    \n    return (W = W, H = H, Hs = vec(sum(H,dims = 1)), Nh = sum(H .!= 0, dims = 1))\nend\n\nfarm_salmon_sim (generic function with 2 methods)\n\n\n\ntest = [farm_salmon_sim(N_t0, T, mu, mW_t0, sdW_t0, W_max, gr, Tw).Hs for j in 1:300];\n\n\nMW = map(mean, eachcol(stack(test, dims = 1)))\nSW = map(std, eachcol(stack(test, dims = 1)))\n\ncMW = map(mean,eachcol(stack(cumsum.(test), dims = 1)))\ncSW = map(std,eachcol(stack(cumsum.(test), dims = 1)))\n\np1 = plot(1:(T+1), MW, ribbon = 1.96 .* SW ./ sqrt(300), title = \"Weekly harvested biomass\")\np2 = plot(1:(T+1), cMW, ribbon = 1.96 .* cSW ./ sqrt(300), title = \"Cumulative harvested biomass\")\nplot(p1, p2, layout=(1,2), size=(750,300))"
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#introduction",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#introduction",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "title": "Heart rate recovery analysis",
    "section": "2 Experiment and data collection",
    "text": "2 Experiment and data collection\nHeart rate data were collected (on a single individual over months of training sessions) using a wearable heart rate watch immediately following a 30-minute running session on a treadmill. The standardized workout comprised three phases: the first 15 minutes at 6.5 miles per hour, the next 10 minutes at 7.0 miles per hour, and the final 5 minutes at 7.5 miles per hour. Data collection began at the instant the 30-minute workout concluded (time t=0) and continued for the subsequent 5 to 20 minutes post-exercise, capturing the heart rate recovery phase. The wearable watch, equipped with an optical heart rate sensor, was configured to record heart rate data at a 5-second granularity, yielding 12 measurements per minute (60 seconds ÷ 5 seconds). Over the 15-minute recovery window (from 5 to 20 minutes, or 900 seconds), this resulted in 180 data points (900 seconds ÷ 5 seconds). The watch was securely worn on the wrist to ensure accurate and consistent measurements, with data stored locally on the device and later exported for analysis. Timestamps were aligned to the end of the workout to precisely track the heart rate decrease during the recovery period, enabling detailed analysis of cardiovascular recovery dynamics following the standardized treadmill session."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#statistical-model",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#statistical-model",
    "title": "Heart rate recovery analysis",
    "section": "3 Statistical model",
    "text": "3 Statistical model\nTo model the heart rate decrease during the recovery phase following a 30-minute standardized treadmill running session, we adopted a non-linear mixed effects (NLME) model, informed by peer-reviewed literature on heart rate recovery dynamics (See [1], [2], [3], [4], [5]). The recovery phase, spanning from 0 to 20 minutes post-exercise with heart rate data collected at 5-second intervals, exhibits a non-linear decay pattern, as heart rate typically decreases rapidly initially and then stabilizes over time. This non-linear behavior, combined with inter-session variability (e.g., due to fitness levels or training frequency) and the hierarchical nature of the data (repeated measurements within sessions), makes an NLME model suitable. Peer-reviewed studies, such as those in exercise physiology, highlight NLME models as effective for capturing both individual-level trends and session-specific variations in heart rate recovery, accounting for factors like the number of training sessions in the past two weeks.\nThe NLME model can be expressed as follows:\n\\[y_{ij} = f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i) + \\epsilon_{ij}\\]\nwhere:\n\n\\(y_{ij}\\): Heart rate measurement for individual \\(i\\) at time point \\(j\\),\n\\(f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i)\\): Non-linear function describing the heart rate recovery trajectory, dependent on time \\(x_{ij}\\), fixed effect parameters \\(\\boldsymbol{\\beta}\\), and individual-specific random effects \\(\\boldsymbol{b}_i\\),\n\\(\\boldsymbol{b}_i \\sim N(0, \\boldsymbol{\\Psi})\\): Random effects vector, assumed to follow a multivariate normal distribution with covariance matrix \\(\\boldsymbol{\\Psi}\\),\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): Residual error, assumed to be normally distributed with variance \\(\\sigma^2\\).\n\nThe negative exponential shape function was chosen because heart rate recovery typically exhibits a rapid initial decline followed by a slower stabilization, a pattern well-captured by this form. Peer-reviewed studies in exercise physiology support its use, as it effectively models the physiological process of cardiovascular recovery. Additionally, its parameters allow interpretable insights into amplitude, decay rate, and asymptotic heart rate, aligning with the data’s non-linear dynamics. The model for heart rate recovery is specified as: \\[y_{ij} = a_i \\cdot \\exp(-b_i \\cdot t_{ij}) + k + \\epsilon_{ij}\\] where:\n\n\\(y_{ij}\\): heart rate measurement for session \\(i\\) at time point \\(j\\)\n\\(t_{ij}\\): time since the end of the workout for session \\(i\\) at measurement \\(j\\)\n\\(a_i = \\alpha_0 + \\alpha_1 \\cdot \\text{training}_i + u_i\\): amplitude parameter for session \\(i\\), with \\(\\alpha_0\\) as the fixed intercept, \\(\\alpha_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(u_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(b_i = \\beta_0 + \\beta_1 \\cdot \\text{training}_i + v_i\\): decay rate parameter for session \\(i\\), with \\(\\beta_0\\) as the fixed intercept and \\(\\beta_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(v_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(k\\): Asymptotic heart rate, assumed constant across sessions,\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): residual error, assumed normally distributed with variance \\(\\sigma^2\\)\n\nThis model captures the non-linear heart rate recovery trajectory, incorporating the effect of training frequency as a fixed effect and session-specific variability through a random intercept."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#r-code",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#r-code",
    "title": "Heart rate recovery analysis",
    "section": "4 R code",
    "text": "4 R code\nTo analyze the heart rate recovery data and model the non-linear decrease following the standardized treadmill workout, we will utilize the R programming environment in conjunction with the brms package, which interfaces with Stan for Bayesian statistical modeling. This approach enables robust fitting of the non-linear mixed effects model, leveraging Stan’s powerful Markov Chain Monte Carlo (MCMC) sampling to estimate model parameters while accounting for both fixed and random effects. The brms package provides a user-friendly framework to specify complex models, incorporate covariates such as the number of training sessions in the past two weeks, and handle the hierarchical structure of the data efficiently. See [6].\nWe load useful R libraries to handle data and bayesian model:\n\nlibrary(data.table)\nlibrary(gridExtra)\nlibrary(bayesplot)\nlibrary(cmdstanr)\nlibrary(ggplot2)\nlibrary(arrow)\nlibrary(brms)\n\nWe visualize the experimental data that are used for the statistical model\n\ndt_test = read_parquet(\"dataset.parquet\")\nt1 = ggplot(dt_test) +\n  geom_line(aes(x = time, y = hr, group = date), alpha = 0.3) +\n  geom_smooth(aes(x = time, y = hr)) +\n  labs(title = \"Experimental data\") + \n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\nt2 = ggplot(dt_test) +\n  geom_boxplot(aes(x = as.factor(time), y = hr), fill = \"#69b3a2\",alpha = 0.3) +\n  labs(title = \"Experimental data\") + \n  scale_x_discrete(breaks = seq(0,15)) +\n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\ngrid.arrange(t1,t2,ncol = 2)\n\n\n\n\n\n\n\n\nIn this block we have the code for the bayesian no-linear mixed effect model. We leverage STAN bayesian framework through brms package. The coefficient \\(b\\) need to be positive (in order to have \\(-b\\) always negative) but the intercept and coefficient of \\(\\text{training}_i\\) can be positive or negative, for this reason we estimate the \\(log(b)\\) and then we exponentiate the variable logb to get our final results. We select priors and the initial points based on literature and data observations.\n\nfit_exponential &lt;- brms::brm(\n  formula = brms::bf(hr ~ a * exp(-exp(logb) * time) + k, \n                     a + logb ~ 1 + N_train + (1 | date),\n                     k ~ 1,\n                     nl=TRUE),\n  data = dt_test,\n  cores = 4,\n  backend = \"cmdstan\",\n  init = replicate(4,list(b_a_Intercept = 95       # Fixed intercept for a\n                          ,b_a_N_train = 0         # Effect of N_train on a\n                          ,b_b_Intercept = 0\n                          ,b_b_N_train = 0\n                          ,b_k_Intercept = 90\n                          ), \n                   simplify = F),\n  seed = 85538,\n  prior   = c(prior(normal(96,1), nlpar = \"a\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"a\", coef=\"N_train\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"N_train\"),\n              prior(normal(90,1), nlpar = \"k\", lb = 0)),\n  control = list(adapt_delta = 0.99,\n                 max_treedepth = 15),\n  file = \"nlme_gps/fit_exp_re_cov.rds\"\n)\n\nLet’s see the results of the analysis\n\nfit_exponential\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: hr ~ a * exp(-exp(logb) * time) + k \n         a ~ 1 + N_train + (1 | date)\n         logb ~ 1 + N_train + (1 | date)\n         k ~ 1\n   Data: dt_test (Number of observations: 1937) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~date (Number of levels: 74) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(a_Intercept)        6.27      0.99     4.46     8.38 1.00     1382     2197\nsd(logb_Intercept)     0.27      0.03     0.22     0.32 1.00      942     1796\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\na_Intercept       94.25      0.86    92.55    96.00 1.00     2606     2484\na_N_train         -1.09      0.31    -1.70    -0.51 1.00     2316     2437\nlogb_Intercept    -0.95      0.06    -1.06    -0.84 1.01      842     1547\nlogb_N_train      -0.01      0.02    -0.04     0.02 1.00      641     1592\nk_Intercept       92.74      0.32    92.11    93.34 1.00     8288     2942\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.26      0.12     7.03     7.50 1.00     5952     2999\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe model implemented demonstrates robust convergence with all Rhat values at or very close to 1.0. The model characterizes an exponential decay function with a Gaussian distribution, revealing a baseline parameter estimate of 94.25 (95% CI: 92.55-96.00) that exhibits a significant negative effect (-1.09, 95% CI: -1.70 to -0.51) proportional to the number pf training in the previous 14 days. The log decay rate is estimated at -0.95 (95% CI: -1.06 to -0.84), with minimal influence from training in the previous 14 days(-0.01, 95% CI: -0.04 to 0.02). The response asymptotes (not a mathematical one but it’s the value where the heart rate decrease slow down) at approximately 92.74 (95% CI: 92.11-93.34). Notable random effects include substantial between-date variability in the baseline parameter (SD=6.27) and moderate variability in decay rate (SD=0.27), while the residual standard deviation is 7.26 (95% CI: 7.03-7.50). All parameters demonstrate adequate effective sample sizes for reliable estimation."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#references",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#references",
    "title": "Heart rate recovery analysis",
    "section": "5 References",
    "text": "5 References\n\n\n[1] G. L. Pierpont, S. Adabag, and D. Yannopoulos, “Pathophysiology of exercise heart rate recovery: A comprehensive analysis,” Annals of Noninvasive Electrocardiology, vol. 18, no. 2, pp. 107–117, 2013, doi: https://doi.org/10.1111/anec.12061.\n\n\n[2] C. R. Cole, E. H. Blackstone, F. J. Pashkow, C. E. Snader, and M. S. Lauer, “Heart-rate recovery immediately after exercise as a predictor of mortality,” New England Journal of Medicine, vol. 341, no. 18, pp. 1351–1357, 1999, doi: 10.1056/NEJM199910283411804.\n\n\n[3] H. A. M. Daanen, R. P. Lamberts, V. L. Kallen, A. Jin, and N. L. U. V. Meeteren, “A systematic review on heart-rate recovery to monitor changes in training status in athletes,” International Journal of Sports Physiology and Performance, vol. 7, no. 3, pp. 251–260, 2012, doi: 10.1123/ijspp.7.3.251.\n\n\n[4] T. P. Facioli et al., “Study of heart rate recovery and cardiovascular autonomic modulation in healthy participants after submaximal exercise,” Scientific Reports, vol. 11, no. 1, p. 3620, Feb. 2021, doi: 10.1038/s41598-021-83071-w.\n\n\n[5] R. X. da Fonseca, C. J. Gomes da Cruz, E. de M. K. V. K. Soares, G. L. Garcia, L. G. G. Porto, and G. E. Molina, “Post-exercise heart rate recovery and its speed are associated with resting-reactivity cardiovagal modulation in healthy women,” Scientific Reports, vol. 14, no. 1, p. 5526, Mar. 2024, doi: 10.1038/s41598-024-51842-w.\n\n\n[6] M. Franke, “Bayesian Regression: Theory &amp; Practice - Non-linear models in brms — michael-franke.github.io.” https://michael-franke.github.io/Bayesian-Regression/practice-sheets/10a-nonLinear.html."
  },
  {
    "objectID": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#appendix",
    "href": "projects/portfolio/nlme_gps/gps_analysis_nlme.html#appendix",
    "title": "Heart rate recovery analysis",
    "section": "6 Appendix",
    "text": "6 Appendix\nAutocorrelation\n\nparameters = c(\"b_a_Intercept\",\"b_a_N_train\",\"b_logb_Intercept\",\n               \"b_logb_N_train\",\"b_k_Intercept\",\"sd_date__a_Intercept\",\n               \"sd_date__logb_Intercept\",\"sigma\")\nmcmc_acf(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nPosterior density\n\nmcmc_dens(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nTraceplot after warmup\n\nmcmc_trace(fit_exponential, pars = parameters)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nicoló Foppa Pedretti",
    "section": "",
    "text": "Quantitative Data Scientist with over 8 years of experience bridging research, energy, and finance. My expertise lies in statistical modeling, machine learning, and Bayesian methods, backed by a strong publication record in peer-reviewed journals. Whether it’s developing disease progression models for Alzheimer’s research or optimizing investment portfolios through advanced time series analysis, I thrive on turning complex data into actionable insights.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#contacts",
    "href": "index.html#contacts",
    "title": "Nicoló Foppa Pedretti",
    "section": "Contacts",
    "text": "Contacts\n\nnicolo.fp@gmail.com\nGitHub\nLinkedIn\nResume",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Extended Resume",
    "section": "",
    "text": "Quantitative Data Scientist with over 8 years of experience bridging research, energy, and finance. My expertise lies in statistical modeling, machine learning, and Bayesian methods, backed by a strong publication record in peer-reviewed journals. Whether it’s developing disease progression models for Alzheimer’s research, optimizing investment portfolios through advanced time series analysis, or forecasting commodity prices in the energy sector to identify profitable opportunities, I thrive on turning complex data into actionable insights. From engineering automated data pipelines to transform clinical trial information into analysis-ready formats, to crafting custom statistical packages for environmental health studies, I’ve honed my mathematical prowess across diverse tools and environments. At the Icahn School of Medicine, I delved into multi-omics datasets using dimensionality reduction methods, uncovering biomarkers that drive real-world impact. In finance, I applied forecasting models and optimization strategies to detect trading patterns and maximize risk-adjusted returns, while in energy, I built mathematical models for portfolio monitoring and risk control, drawing on data mining to enhance market intelligence. This diverse background—from healthcare innovations to financial strategies and energy market dynamics—fuels cross-fertilization of ideas, allowing me to apply insights from one field to solve challenges in another. With a Master’s in Statistics and Bachelor’s in Applied Mathematics from top Italian universities, I’m passionate about leveraging these skills to solve challenging problems",
    "crumbs": [
      "Basics",
      "Extended resume"
    ]
  },
  {
    "objectID": "about.html#introduction",
    "href": "about.html#introduction",
    "title": "Extended Resume",
    "section": "",
    "text": "Quantitative Data Scientist with over 8 years of experience bridging research, energy, and finance. My expertise lies in statistical modeling, machine learning, and Bayesian methods, backed by a strong publication record in peer-reviewed journals. Whether it’s developing disease progression models for Alzheimer’s research, optimizing investment portfolios through advanced time series analysis, or forecasting commodity prices in the energy sector to identify profitable opportunities, I thrive on turning complex data into actionable insights. From engineering automated data pipelines to transform clinical trial information into analysis-ready formats, to crafting custom statistical packages for environmental health studies, I’ve honed my mathematical prowess across diverse tools and environments. At the Icahn School of Medicine, I delved into multi-omics datasets using dimensionality reduction methods, uncovering biomarkers that drive real-world impact. In finance, I applied forecasting models and optimization strategies to detect trading patterns and maximize risk-adjusted returns, while in energy, I built mathematical models for portfolio monitoring and risk control, drawing on data mining to enhance market intelligence. This diverse background—from healthcare innovations to financial strategies and energy market dynamics—fuels cross-fertilization of ideas, allowing me to apply insights from one field to solve challenges in another. With a Master’s in Statistics and Bachelor’s in Applied Mathematics from top Italian universities, I’m passionate about leveraging these skills to solve challenging problems",
    "crumbs": [
      "Basics",
      "Extended resume"
    ]
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "Extended Resume",
    "section": "Work Experience",
    "text": "Work Experience\n\nQuantitative Medicine Scientist (Data Scientist) – Pharmacometrics | Critical Path Institute, Remote, US | September 2024 – Present\n\nDeveloped disease progression models using linear/non-linear mixed effects frameworks in R and Stan, applying frequentist and Bayesian approaches to analyze longitudinal Alzheimer’s data and identify predictive biomarkers.\nEngineered automated ETL pipelines in R to transform clinical trial data from SDTM/ADaM standards into analysis-ready datamarts with comprehensive data quality checks and validation procedures.\n\nBiostatistician II (Data Scientist) | Icahn School of Medicine at Mount Sinai, New York, NY | February 2019 – April 2024\n\nAnalyzed multi-omics datasets (metabolomics, epigenetics) using machine learning, dimensionality reduction (PCA, t-SNE, UMAP), and linear mixed-effects models for biomarker identification and pathway validation in R.\nDeveloped Bayesian mixture regression R package using Stan and applied advanced time series models (Distributed Lag Models, ARIMA, Bayesian splines, Gaussian State Space Models) for environmental health analysis using Stan, JAGS, and R.\nImplemented machine learning pipelines (XGBoost, tree-based models, polynomial regression) for biomarker prediction and validation on large-scale genomic data using R and Julia.\nBuilt automated ETL pipelines and reproducible workflows using SQL, R, and DuckDB, generating publication-ready reports with RMarkdown/Quarto, ggplot2, and plotly for peer-reviewed publications.\nConducted EWAS (environment-wide association studies) on placenta methylation and child blood pressure; developed BWQS algorithms for PFAS exposure and bone mineral density; applied DLNM on pregnancy environmental data for maternal outcomes; investigated metal exposures on fetal antibody responses; used Bayesian Factor Analysis for metabolite effects on birth weight; developed HBWQS for chemical mixtures across cohorts.\n\nQuantitative Analyst – R&D | InchCapital, Milan, Italy | April 2017 – December 2018\n\nExecuted time series analysis using ARIMA and Hidden Markov Models with harmonic regression to detect trading patterns and anomalies, designing quantitative strategies across multi-asset portfolios with rigorous back-testing and Monte Carlo simulations using R, Python, and Julia.\nOptimized investment portfolios using Markowitz theory and advanced peer-reviewed methodologies to maximize risk-adjusted returns, establishing key performance metrics and automated executive reporting systems using R/RMarkdown for management and client deliverables.\n\nData Scientist – Market Intelligence and Risk Control | Gala S.p.A., Milan, Italy | June 2016 – November 2018\n\nBuilt mathematical and statistical models for portfolio performance monitoring and commodity price forecasting, applying machine learning and data mining techniques to energy time series data to identify profitable trading opportunities using R.\nValidated and optimized quantitative trading models while managing ETL processes across PostgreSQL databases, deploying parallel processing solutions on Linux servers and automating workflows through custom RShiny applications using R and SQL.",
    "crumbs": [
      "Basics",
      "Extended resume"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Extended Resume",
    "section": "Education",
    "text": "Education\n\nMaster of Science in Statistics | Universitá degli Studi Milano-Bicocca, Milan, Italy | September 2013 – January 2016\n\nFocused on advanced probability theory, statistical inference, statistical computing, linear models, econometric methods (panel data analysis, time series analysis, forecasting), risk management, financial modeling with R applications, and multivariate statistics (principal component analysis, factor analysis, cluster analysis).\nPrepared for careers in data analysis, research, and consulting in finance and healthcare.\n\nBachelor of Science in Applied Mathematics | Universitá degli Studi di Milano, Milan, Italy | September 2009 – December 2013\n\nCovered algebra, calculus, linear algebra, calculus of several variables, differential equations, Euclidean geometry, differential geometry, topology, numerical analysis (numerical integration, root-finding, solving differential equations using C/C++ and MATLAB), mechanics, electromagnetism, thermodynamics, and quantum mechanics.\nBuilt skills in mathematical modeling and analysis for applications in engineering, computer science, finance, and research.",
    "crumbs": [
      "Basics",
      "Extended resume"
    ]
  },
  {
    "objectID": "add_resume.html",
    "href": "add_resume.html",
    "title": "List of publications",
    "section": "",
    "text": "During my role as Biostatistician at the Icahn School of Medicine at Mount Sinai, I specialized in multi-omics data analysis, working with metabolomics and epigenetic datasets using machine learning techniques, dimensionality reduction methods like PCA, and t-SNE, and mixed-effects models for biomarker identification and biological pathway validation. Below is a list of peer-reviewed publications featuring my contributions: [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12].\n\nList of publications\n\n\n[1] E. Colicino, N. F. Pedretti, S. A. Busgang, and C. Gennings, “Per- and poly-fluoroalkyl substances and bone mineral density: Results from the bayesian weighted quantile sum regression,” Environmental Epidemiology, vol. 4, no. 3, 2020, [Online]. Available: https://journals.lww.com/environepidem/fulltext/2020/06000/per__and_poly_fluoroalkyl_substances_and_bone.3.aspx.\n\n\n[2] E. Colicino et al., “Prenatal exposure to multiple organochlorine compounds and childhood body mass index,” Environmental Epidemiology, vol. 6, no. 3, 2022, [Online]. Available: https://journals.lww.com/environepidem/fulltext/2022/06000/prenatal_exposure_to_multiple_organochlorine.2.aspx.\n\n\n[3] E. Colicino et al., “Cross-cohort mixture analysis: A data integration approach with applications on gestational age and DNA-methylation-derived gestational age acceleration metrics,” medRxiv, 2023, doi: 10.1101/2023.04.14.23288581.\n\n\n[4] H. M. Thompson et al., “The development of frailty trajectories in world trade center general responders and the association with world trade center exposure,” The Journal of Frailty & Aging, vol. 14, no. 2, p. 100027, 2025, doi: https://doi.org/10.1016/j.tjfa.2025.100027.\n\n\n[5] M. J. Rosa et al., “Integrating data across multiple sites in the northeastern united states to examine associations between a prenatal metal mixture and child cognition,” American Journal of Epidemiology, vol. 193, no. 4, pp. 606–616, Nov. 2023, doi: 10.1093/aje/kwad233.\n\n\n[6] C. S. Alcala et al., “Prenatal exposure to phthalates and childhood wheeze and asthma in the PROGRESS cohort,” Science of The Total Environment, vol. 954, p. 176311, 2024, doi: https://doi.org/10.1016/j.scitotenv.2024.176311.\n\n\n[7] D. Carrión et al., “Neighborhood-level disparities and subway utilization during the COVID-19 pandemic in new york city,” Nature Communications, vol. 12, no. 1, p. 3692, Jun. 2021, doi: 10.1038/s41467-021-24088-7.\n\n\n[8] E. Colicino et al., “Maternal steroids during pregnancy and their associations with ambient air pollution and temperature during preconception and early gestational periods,” Environment International, vol. 165, p. 107320, 2022, doi: https://doi.org/10.1016/j.envint.2022.107320.\n\n\n[9] L. Gerbi et al., “Biomarkers of maternal lead exposure during pregnancy using micro-spatial child deciduous dentine measurements,” Environment International, vol. 169, p. 107529, 2022, doi: https://doi.org/10.1016/j.envint.2022.107529.\n\n\n[10] E. Colicino et al., “Prenatal urinary concentrations of phthalate metabolites and behavioral problems in mexican children: The programming research in obesity, growth environment and social stress (PROGRESS) study,” Environmental Research, vol. 201, p. 111338, 2021, doi: https://doi.org/10.1016/j.envres.2021.111338.\n\n\n[11] E. Colicino et al., “Non-linear and non-additive associations between the pregnancy metabolome and birthweight,” Environment International, vol. 156, p. 106750, 2021, doi: https://doi.org/10.1016/j.envint.2021.106750.\n\n\n[12] E. Colicino et al., “Association between prenatal immune phenotyping and cord blood leukocyte telomere length in the PRISM pregnancy cohort,” Environmental Research, vol. 191, p. 110113, 2020, doi: https://doi.org/10.1016/j.envres.2020.110113.",
    "crumbs": [
      "Basics",
      "Publications"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html",
    "href": "projects/gps/gps_analysis_nlme.html",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#introduction",
    "href": "projects/gps/gps_analysis_nlme.html#introduction",
    "title": "Heart rate recovery analysis",
    "section": "",
    "text": "The advent of wearable technology, such as heart rate watches, has revolutionized the way individuals monitor and optimize their fitness and health. These devices provide continuous, real-time data on heart rate, offering valuable insights into cardiovascular responses during and after physical activity. This analysis aims to model the heart rate decrease following a standardized workout, a key indicator of cardiovascular recovery and fitness level. By leveraging heart rate data, we seek to understand how factors such as the number of training sessions in the past two weeks influence the rate of heart rate recovery. This study will explore the interplay between training frequency and recovery dynamics, providing a foundation for personalized fitness recommendations and enhanced training protocols. Through statistical modeling, we aim to uncover patterns that can inform athletes, coaches, and fitness enthusiasts about optimizing workout regimens for improved performance and health outcomes.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "href": "projects/gps/gps_analysis_nlme.html#experiment-and-data-collection",
    "title": "Heart rate recovery analysis",
    "section": "2 Experiment and data collection",
    "text": "2 Experiment and data collection\nHeart rate data were collected (on a single individual over months of training sessions) using a wearable heart rate watch immediately following a 30-minute running session on a treadmill. The standardized workout comprised three phases: the first 15 minutes at 6.5 miles per hour, the next 10 minutes at 7.0 miles per hour, and the final 5 minutes at 7.5 miles per hour. Data collection began at the instant the 30-minute workout concluded (time t=0) and continued for the subsequent 5 to 20 minutes post-exercise, capturing the heart rate recovery phase. The wearable watch, equipped with an optical heart rate sensor, was configured to record heart rate data at a 5-second granularity, yielding 12 measurements per minute (60 seconds ÷ 5 seconds). Over the 15-minute recovery window (from 5 to 20 minutes, or 900 seconds), this resulted in 180 data points (900 seconds ÷ 5 seconds). The watch was securely worn on the wrist to ensure accurate and consistent measurements, with data stored locally on the device and later exported for analysis. Timestamps were aligned to the end of the workout to precisely track the heart rate decrease during the recovery period, enabling detailed analysis of cardiovascular recovery dynamics following the standardized treadmill session.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#statistical-model",
    "href": "projects/gps/gps_analysis_nlme.html#statistical-model",
    "title": "Heart rate recovery analysis",
    "section": "3 Statistical model",
    "text": "3 Statistical model\nTo model the heart rate decrease during the recovery phase following a 30-minute standardized treadmill running session, we adopted a non-linear mixed effects (NLME) model, informed by peer-reviewed literature on heart rate recovery dynamics (See [1], [2], [3], [4], [5]). The recovery phase, spanning from 0 to 20 minutes post-exercise with heart rate data collected at 5-second intervals, exhibits a non-linear decay pattern, as heart rate typically decreases rapidly initially and then stabilizes over time. This non-linear behavior, combined with inter-session variability (e.g., due to fitness levels or training frequency) and the hierarchical nature of the data (repeated measurements within sessions), makes an NLME model suitable. Peer-reviewed studies, such as those in exercise physiology, highlight NLME models as effective for capturing both individual-level trends and session-specific variations in heart rate recovery, accounting for factors like the number of training sessions in the past two weeks.\nThe NLME model can be expressed as follows:\n\\[y_{ij} = f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i) + \\epsilon_{ij}\\]\nwhere:\n\n\\(y_{ij}\\): Heart rate measurement for individual \\(i\\) at time point \\(j\\),\n\\(f(x_{ij}, \\boldsymbol{\\beta}, \\boldsymbol{b}_i)\\): Non-linear function describing the heart rate recovery trajectory, dependent on time \\(x_{ij}\\), fixed effect parameters \\(\\boldsymbol{\\beta}\\), and individual-specific random effects \\(\\boldsymbol{b}_i\\),\n\\(\\boldsymbol{b}_i \\sim N(0, \\boldsymbol{\\Psi})\\): Random effects vector, assumed to follow a multivariate normal distribution with covariance matrix \\(\\boldsymbol{\\Psi}\\),\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): Residual error, assumed to be normally distributed with variance \\(\\sigma^2\\).\n\nThe negative exponential shape function was chosen because heart rate recovery typically exhibits a rapid initial decline followed by a slower stabilization, a pattern well-captured by this form. Peer-reviewed studies in exercise physiology support its use, as it effectively models the physiological process of cardiovascular recovery. Additionally, its parameters allow interpretable insights into amplitude, decay rate, and asymptotic heart rate, aligning with the data’s non-linear dynamics. The model for heart rate recovery is specified as: \\[y_{ij} = a_i \\cdot \\exp(-b_i \\cdot t_{ij}) + k + \\epsilon_{ij}\\] where:\n\n\\(y_{ij}\\): heart rate measurement for session \\(i\\) at time point \\(j\\)\n\\(t_{ij}\\): time since the end of the workout for session \\(i\\) at measurement \\(j\\)\n\\(a_i = \\alpha_0 + \\alpha_1 \\cdot \\text{training}_i + u_i\\): amplitude parameter for session \\(i\\), with \\(\\alpha_0\\) as the fixed intercept, \\(\\alpha_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(u_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(b_i = \\beta_0 + \\beta_1 \\cdot \\text{training}_i + v_i\\): decay rate parameter for session \\(i\\), with \\(\\beta_0\\) as the fixed intercept and \\(\\beta_1\\) as the fixed effect of the number of training sessions in the previous two weeks (\\(\\text{training}_i\\)), and \\(v_i \\sim N(0, \\sigma_u^2)\\) as the random intercept for session \\(i\\)\n\\(k\\): Asymptotic heart rate, assumed constant across sessions,\n\\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\): residual error, assumed normally distributed with variance \\(\\sigma^2\\)\n\nThis model captures the non-linear heart rate recovery trajectory, incorporating the effect of training frequency as a fixed effect and session-specific variability through a random intercept.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#r-code",
    "href": "projects/gps/gps_analysis_nlme.html#r-code",
    "title": "Heart rate recovery analysis",
    "section": "4 R code",
    "text": "4 R code\nTo analyze the heart rate recovery data and model the non-linear decrease following the standardized treadmill workout, we will utilize the R programming environment in conjunction with the brms package, which interfaces with Stan for Bayesian statistical modeling. This approach enables robust fitting of the non-linear mixed effects model, leveraging Stan’s powerful Markov Chain Monte Carlo (MCMC) sampling to estimate model parameters while accounting for both fixed and random effects. The brms package provides a user-friendly framework to specify complex models, incorporate covariates such as the number of training sessions in the past two weeks, and handle the hierarchical structure of the data efficiently. See [6].\nWe load useful R libraries to handle data and bayesian model:\n\nlibrary(data.table)\nlibrary(gridExtra)\nlibrary(bayesplot)\nlibrary(cmdstanr)\nlibrary(ggplot2)\nlibrary(arrow)\nlibrary(brms)\n\nWe visualize the experimental data that are used for the statistical model\n\ndt_test = read_parquet(\"dataset.parquet\")\nt1 = ggplot(dt_test) +\n  geom_line(aes(x = time, y = hr, group = date), alpha = 0.3) +\n  geom_smooth(aes(x = time, y = hr)) +\n  labs(title = \"Experimental data\") + \n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\nt2 = ggplot(dt_test) +\n  geom_boxplot(aes(x = as.factor(time), y = hr), fill = \"#69b3a2\",alpha = 0.3) +\n  labs(title = \"Experimental data\") + \n  scale_x_discrete(breaks = seq(0,15)) +\n  ylab(\"Heart Rate\") + xlab(\"Time (min)\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))\n\ngrid.arrange(t1,t2,ncol = 2)\n\n\n\n\n\n\n\n\nIn this block we have the code for the bayesian no-linear mixed effect model. We leverage STAN bayesian framework through brms package. The coefficient \\(b\\) need to be positive (in order to have \\(-b\\) always negative) but the intercept and coefficient of \\(\\text{training}_i\\) can be positive or negative, for this reason we estimate the \\(log(b)\\) and then we exponentiate the variable logb to get our final results. We select priors and the initial points based on literature and data observations.\n\nfit_exponential &lt;- brms::brm(\n  formula = brms::bf(hr ~ a * exp(-exp(logb) * time) + k, \n                     a + logb ~ 1 + N_train + (1 | date),\n                     k ~ 1,\n                     nl=TRUE),\n  data = dt_test,\n  cores = 4,\n  backend = \"cmdstan\",\n  init = replicate(4,list(b_a_Intercept = 95       # Fixed intercept for a\n                          ,b_a_N_train = 0         # Effect of N_train on a\n                          ,b_b_Intercept = 0\n                          ,b_b_N_train = 0\n                          ,b_k_Intercept = 90\n                          ), \n                   simplify = F),\n  seed = 85538,\n  prior   = c(prior(normal(96,1), nlpar = \"a\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"a\", coef=\"N_train\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"Intercept\"),\n              prior(normal(0,1), nlpar = \"logb\", coef=\"N_train\"),\n              prior(normal(90,1), nlpar = \"k\", lb = 0)),\n  control = list(adapt_delta = 0.99,\n                 max_treedepth = 15),\n  file = \"nlme_gps/fit_exp_re_cov.rds\"\n)\n\nLet’s see the results of the analysis\n\nfit_exponential\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: hr ~ a * exp(-exp(logb) * time) + k \n         a ~ 1 + N_train + (1 | date)\n         logb ~ 1 + N_train + (1 | date)\n         k ~ 1\n   Data: dt_test (Number of observations: 1937) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~date (Number of levels: 74) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(a_Intercept)        6.27      0.99     4.46     8.38 1.00     1382     2197\nsd(logb_Intercept)     0.27      0.03     0.22     0.32 1.00      942     1796\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\na_Intercept       94.25      0.86    92.55    96.00 1.00     2606     2484\na_N_train         -1.09      0.31    -1.70    -0.51 1.00     2316     2437\nlogb_Intercept    -0.95      0.06    -1.06    -0.84 1.01      842     1547\nlogb_N_train      -0.01      0.02    -0.04     0.02 1.00      641     1592\nk_Intercept       92.74      0.32    92.11    93.34 1.00     8288     2942\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.26      0.12     7.03     7.50 1.00     5952     2999\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe model implemented demonstrates robust convergence with all Rhat values at or very close to 1.0. The model characterizes an exponential decay function with a Gaussian distribution, revealing a baseline parameter estimate of 94.25 (95% CI: 92.55-96.00) that exhibits a significant negative effect (-1.09, 95% CI: -1.70 to -0.51) proportional to the number pf training in the previous 14 days. The log decay rate is estimated at -0.95 (95% CI: -1.06 to -0.84), with minimal influence from training in the previous 14 days(-0.01, 95% CI: -0.04 to 0.02). The response asymptotes (not a mathematical one but it’s the value where the heart rate decrease slow down) at approximately 92.74 (95% CI: 92.11-93.34). Notable random effects include substantial between-date variability in the baseline parameter (SD=6.27) and moderate variability in decay rate (SD=0.27), while the residual standard deviation is 7.26 (95% CI: 7.03-7.50). All parameters demonstrate adequate effective sample sizes for reliable estimation.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#references",
    "href": "projects/gps/gps_analysis_nlme.html#references",
    "title": "Heart rate recovery analysis",
    "section": "5 References",
    "text": "5 References\n\n\n[1] G. L. Pierpont, S. Adabag, and D. Yannopoulos, “Pathophysiology of exercise heart rate recovery: A comprehensive analysis,” Annals of Noninvasive Electrocardiology, vol. 18, no. 2, pp. 107–117, 2013, doi: https://doi.org/10.1111/anec.12061.\n\n\n[2] C. R. Cole, E. H. Blackstone, F. J. Pashkow, C. E. Snader, and M. S. Lauer, “Heart-rate recovery immediately after exercise as a predictor of mortality,” New England Journal of Medicine, vol. 341, no. 18, pp. 1351–1357, 1999, doi: 10.1056/NEJM199910283411804.\n\n\n[3] H. A. M. Daanen, R. P. Lamberts, V. L. Kallen, A. Jin, and N. L. U. V. Meeteren, “A systematic review on heart-rate recovery to monitor changes in training status in athletes,” International Journal of Sports Physiology and Performance, vol. 7, no. 3, pp. 251–260, 2012, doi: 10.1123/ijspp.7.3.251.\n\n\n[4] T. P. Facioli et al., “Study of heart rate recovery and cardiovascular autonomic modulation in healthy participants after submaximal exercise,” Scientific Reports, vol. 11, no. 1, p. 3620, Feb. 2021, doi: 10.1038/s41598-021-83071-w.\n\n\n[5] R. X. da Fonseca, C. J. Gomes da Cruz, E. de M. K. V. K. Soares, G. L. Garcia, L. G. G. Porto, and G. E. Molina, “Post-exercise heart rate recovery and its speed are associated with resting-reactivity cardiovagal modulation in healthy women,” Scientific Reports, vol. 14, no. 1, p. 5526, Mar. 2024, doi: 10.1038/s41598-024-51842-w.\n\n\n[6] M. Franke, “Bayesian Regression: Theory &amp; Practice - Non-linear models in brms — michael-franke.github.io.” https://michael-franke.github.io/Bayesian-Regression/practice-sheets/10a-nonLinear.html.",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/gps/gps_analysis_nlme.html#appendix",
    "href": "projects/gps/gps_analysis_nlme.html#appendix",
    "title": "Heart rate recovery analysis",
    "section": "6 Appendix",
    "text": "6 Appendix\nAutocorrelation\n\nparameters = c(\"b_a_Intercept\",\"b_a_N_train\",\"b_logb_Intercept\",\n               \"b_logb_N_train\",\"b_k_Intercept\",\"sd_date__a_Intercept\",\n               \"sd_date__logb_Intercept\",\"sigma\")\nmcmc_acf(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nPosterior density\n\nmcmc_dens(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nTraceplot after warmup\n\nmcmc_trace(fit_exponential, pars = parameters)\n\n\n\n\n\n\n\n\nNote: add model selection + additional postprocess",
    "crumbs": [
      "Projects",
      "Heart rate recovery analysis"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html",
    "href": "projects/portfolio/salmon/salmon_farming.html",
    "title": "Salmon farming model",
    "section": "",
    "text": "This model describes the dynamics of a salmon population in an aquaculture setting, accounting for growth, mortality, and harvesting based on a Gaussian weight distribution. Harvesting targets salmon with weights \\(w \\geq 5\\text{kg}\\). The model tracks the remaining population (number (\\(N\\)), mean weight (\\(W\\)), variance (\\(V\\))) and the cumulative harvested population (number (\\(N_{\\text{h}}\\)), mean weight (\\(W_{\\text{h}}\\)), variance (\\(V_{\\text{h}}\\))), along with some parameters (mortality rate (\\(\\mu\\)), growth rate (\\(g_r\\))). The total biomass is computed as \\(B = N \\cdot W\\).\nVariables:\n\nRemaining Population:\n\n\\(N(t)\\): Number of salmon (dimensionless)\n\\(W(t)\\): Mean weight of remaining salmon (kg)\n\\(V(t)\\): Variance of remaining salmon weights (kg2)\n\nHarvested Population:\n\n\\(N_{\\text{h}}\\): Cumulative number of h salmon (dimensionless)\n\\(W_{\\text{h}}\\): Cumulative mean weight of h salmon (kg)\n\\(V_{\\text{h}}\\): Cumulative variance of h salmon weights ((kg2)\n\n\nThe derived output is the total biomass of remaining salmon (kg), \\(B(t) = N(t) \\cdot W(t)\\). See [1], [2], [3]",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html#introduction",
    "href": "projects/portfolio/salmon/salmon_farming.html#introduction",
    "title": "Salmon farming model",
    "section": "",
    "text": "This model describes the dynamics of a salmon population in an aquaculture setting, accounting for growth, mortality, and harvesting based on a Gaussian weight distribution. Harvesting targets salmon with weights \\(w \\geq 5\\text{kg}\\). The model tracks the remaining population (number (\\(N\\)), mean weight (\\(W\\)), variance (\\(V\\))) and the cumulative harvested population (number (\\(N_{\\text{h}}\\)), mean weight (\\(W_{\\text{h}}\\)), variance (\\(V_{\\text{h}}\\))), along with some parameters (mortality rate (\\(\\mu\\)), growth rate (\\(g_r\\))). The total biomass is computed as \\(B = N \\cdot W\\).\nVariables:\n\nRemaining Population:\n\n\\(N(t)\\): Number of salmon (dimensionless)\n\\(W(t)\\): Mean weight of remaining salmon (kg)\n\\(V(t)\\): Variance of remaining salmon weights (kg2)\n\nHarvested Population:\n\n\\(N_{\\text{h}}\\): Cumulative number of h salmon (dimensionless)\n\\(W_{\\text{h}}\\): Cumulative mean weight of h salmon (kg)\n\\(V_{\\text{h}}\\): Cumulative variance of h salmon weights ((kg2)\n\n\nThe derived output is the total biomass of remaining salmon (kg), \\(B(t) = N(t) \\cdot W(t)\\). See [1], [2], [3]",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html#assumptions",
    "href": "projects/portfolio/salmon/salmon_farming.html#assumptions",
    "title": "Salmon farming model",
    "section": "2 Assumptions",
    "text": "2 Assumptions\n\nThe initial salmon weight will follow a normal distribution with a specified mean (\\(\\mu_0\\)) and standard deviation (\\(\\sigma_0\\)), and harvesting will target salmon above 5kg based on this distribution. Since modeling a full size distribution typically requires partial differential equations (PDEs) for continuous weight classes, we’ll approximate the size structure with a simplified ODE system by tracking the moments of the distribution.\nAssume the weight distribution remains approximately Gaussian over time, \\(W(t) \\sim \\mathcal{N}(W(t), V(t))\\), where \\(W(t)\\) is the mean and \\(\\sqrt{V(t)}\\) is the standard deviation.\nHarvesting removes salmon with \\(w \\geq 5\\), calculated using the cumulative distribution function (CDF) of the normal distribution: \\[\\text{Fraction harvested} = P(w \\geq 5) = 1 - \\Phi\\left(\\frac{5 - W(t)}{\\sqrt{V(t)}}\\right) \\qquad \\text{where } \\Phi \\text{ is the standard normal CDF.}\\]\nHarvesting affects \\(N\\), \\(W\\), and \\(V\\), as larger salmon are removed, shifting the mean and variance.\nWe express the post-harvest mean weight (\\(W_{\\text{post}}\\)) and variance (\\(V_{\\text{post}}\\)) as the conditional mean and variance of a Gaussian distribution truncated below 5kg because harvesting removes salmon with weights \\(w \\geq 5\\text{kg}\\), leaving only those with \\(w&lt;5\\text{kg}\\). We need to compute the mean and variance of this truncated Gaussian distribution for the remaining population (see Section 5 for additional context)\nIn order to include the mean and variance of the harvested salmon weights as state variables in the salmon harvesting model, we need to track the mean weight (\\(W_{\\text{harvested}}\\)) and variance (\\(V_{\\text{harvested}}\\)) of the salmon with weights \\(w \\geq 5\\text{kg}\\) over time. These new state variables will represent the cumulative mean and variance of the harvested salmon, updated as harvesting occurs. Since harvesting is a continuous process in the ODE system, we’ll model the dynamics of \\(W_{\\text{harvested}}\\) and \\(V_{\\text{harvested}}\\) by accumulating the contributions of harvested salmon, weighted by the harvesting rate. New State Variables: \\(W_{\\text{harvested}}(t)\\) (mean weight in kg of all salmon harvested up to time t), \\(V_{\\text{harvested}}\\) (variance of weights in kg2 of all salmon harvested up to time t). However we face some challenges because harvesting is modeled as a continuous rate, so \\(W_{\\text{harvested}}\\) and \\(V_{\\text{harvested}}\\) represent the average properties of the cumulative harvested population. The instantaneous mean and variance of harvested salmon at time t are given by the truncated Gaussian \\(w \\geq 5\\), but we need to track their cumulative effect. As a solution we introduce ODEs for the two parameters that update based on the instantaneous harvested mean and variance, we use an auxiliary state variable \\[\\frac{dN_{\\text{harvested}}}{dt} = h \\left[ 1 - \\Phi\\left(\\frac{5 - W}{\\sqrt{V}}\\right) \\right] N\\] to track the cumulative number of harvested salmon, which helps normalize the mean and variance calculations.\nThe instantaneous mean and variance of harvested salmon at time t, given \\(\\alpha = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\), are: \\[W_{\\text{inst}}(t) = W(t) + \\sqrt{V(t)} \\cdot \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} \\qquad \\qquad V_{\\text{inst}}(t) = V(t) \\left[ 1 + \\frac{\\phi(\\alpha) \\cdot \\alpha}{1 - \\Phi(\\alpha)} - \\left( \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} \\right)^2 \\right]\\] which lead to\n\\[\\begin{array}{l}\n\\frac{dW_{\\text{harvested}}}{dt} = \\frac{h \\left[ 1 - \\Phi\\left(\\frac{5 - W}{\\sqrt{V}}\\right) \\right] N (W_{\\text{inst}} - W_{\\text{harvested}})}{N_{\\text{harvested}} + \\epsilon} \\\\\n\\frac{dV_{\\text{harvested}}}{dt} = \\frac{h \\left[ 1 - \\Phi\\left(\\frac{5 - W}{\\sqrt{V}}\\right) \\right] N [V_{\\text{inst}} + (W_{\\text{inst}} - W_{\\text{harvested}})^2 - V_{\\text{harvested}}]}{N_{\\text{harvested}} + \\epsilon}\n\\end{array}\\]",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html#equation",
    "href": "projects/portfolio/salmon/salmon_farming.html#equation",
    "title": "Salmon farming model",
    "section": "3 Equation",
    "text": "3 Equation\n\\[\\begin{array}{l}\n\\frac{dN}{dt} = -(\\mu + h_r)N \\\\\n\\frac{dW}{dt} = g_r\\left(1 - \\frac{W}{W_{max}} \\right) - h_r(W-W_{post}) \\\\\n\\frac{dV}{dt} = \\sigma^2_gg_r - h_r(V-V_{post}) \\\\\n\\frac{dN_{\\text{h}}}{dt} = h_r N \\\\\n\\frac{dW_{\\text{h}}}{dt} = \\frac{h_r N (W_{\\text{inst}} - W_{\\text{h}})}{N_{\\text{h}} + \\epsilon} \\\\\n\\frac{dV_{\\text{h}}}{dt} = \\frac{h_r N [V_{\\text{inst}} + (W_{\\text{inst}} - W_{\\text{h}})^2 - V_{\\text{h}}]}{N_{\\text{h}} + \\epsilon},\n\\end{array}\\]",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html#references",
    "href": "projects/portfolio/salmon/salmon_farming.html#references",
    "title": "Salmon farming model",
    "section": "4 References",
    "text": "4 References\n\n\n[1] E. Legrand et al., “Salmon farming alters the structure and functioning of norwegian maerl bed communities,” Aquatic Conservation: Marine and Freshwater Ecosystems, vol. 34, no. 4, p. e4142, 2024, doi: https://doi.org/10.1002/aqc.4142.\n\n\n[2] A. C. Harvey et al., “Does density influence relative growth performance of farm, wild and f&lt;sub&gt;1&lt;/sub&gt; hybrid atlantic salmon in semi-natural and hatchery common garden conditions?” Royal Society Open Science, vol. 3, no. 7, p. 160152, 2016, doi: 10.1098/rsos.160152.\n\n\n[3] R. B. M. Pincinato, F. Asche, H. Bleie, A. Skrudland, and M. Stormoen, “Factors influencing production loss in salmonid farming,” Aquaculture, vol. 532, p. 736034, 2021, doi: https://doi.org/10.1016/j.aquaculture.2020.736034.",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_farming.html#sec-appx",
    "href": "projects/portfolio/salmon/salmon_farming.html#sec-appx",
    "title": "Salmon farming model",
    "section": "5 Appendix",
    "text": "5 Appendix\n\n5.1 Truncated Gaussian Distribution\nFor a Gaussian random variable \\(w \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), truncated to \\(w &lt; a\\), the probability density function of the truncated distribution is:\n\\[f(w|w &lt; a) = \\frac{\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(w-\\mu)^2}{2\\sigma^2} \\right) }{\\Phi \\left( \\frac{a-\\mu}{\\sigma} \\right)} \\quad \\text{for } w &lt; a\\]\nwhere \\(\\Phi(z)\\) is the standard normal CDF, and the denominator \\(\\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right) = P(w &lt; a)\\) is the probability of \\(w &lt; a\\). In our case:\n\n\\(\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int^{z}_{-\\infty} e^{\\frac{-u^2}{2}}du\\)\n\\(\\mu = W(t)\\): Mean weight before harvesting\n\\(\\sigma^2 = V(t)\\): Variance before harvesting\n\\(a=5\\): Truncation point (harvest salmon with \\(w \\geq 5\\))\n\nLet’s define:\n\n\\(\\alpha = \\frac{a - \\mu}{\\sigma} = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\): Standardized truncation point\n\\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)\\): Standard normal PDF\n\\(\\Phi(\\alpha) = P(z &lt; \\alpha)\\): CDF at \\(\\alpha\\)\n\nThe fraction of salmon remaining after harvesting is \\(\\Phi(\\alpha)\\), and the fraction harvested is \\(1 - \\Phi(\\alpha)\\).\n\n5.1.1 Conditional Mean (\\(W_{\\text{post}}\\))\nThe mean of a Gaussian distribution truncated at \\(w &lt; a\\), substituting \\(\\mu = W(t)\\), \\(\\sigma = \\sqrt{V(t)}\\), \\(a = 5\\) and \\(\\alpha = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\) is:\n\\[\\mathbb{E}[w|w&lt;a] = \\mu - \\sigma \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)} \\quad \\longrightarrow \\quad W_{\\text{post}} = W(t) - \\sqrt{V(t)} \\frac{\\phi \\left( \\frac{5-W(t)}{\\sqrt{V(t)}}\\right)}{\\Phi \\left( \\frac{5-W(t)}{\\sqrt{V(t)}}\\right)} \\quad \\longrightarrow \\quad W_{\\text{post}} = W(t) - \\sqrt{V(t)} \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\]\nThe term \\(\\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\) is the hazard function (or inverse Mills ratio) for the standard normal, which adjusts the mean downward since larger weights are removed.\n\n\n5.1.2 Conditional Variance (\\(V_{\\text{post}}\\))\nThe variance of the truncated Gaussian \\(w &lt; a\\), substituting \\(\\sigma^2 = V(t)\\), \\(\\mu = W(t)\\), \\(a=5\\), and \\(\\alpha = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\) is:\n\\[Var[w|w&lt;a] = \\sigma^2 \\left[ 1 - \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)  \\frac{a-\\mu}{\\sigma}}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)} - \\left( \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)} \\right)^2 \\right] \\qquad \\longrightarrow \\qquad V_{\\text{post}} = V(t) \\left[ 1 - \\frac{\\phi(\\alpha) \\alpha}{\\Phi(\\alpha)} - \\left( \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)} \\right)^2 \\right]\\] This expression accounts for the reduced variance after removing the upper tail of the distribution. Behavior:\n\nIf \\(W \\ll 5\\), \\(\\alpha\\) is large, \\(\\Phi(\\alpha) \\approx 1\\), \\(\\phi(\\alpha) \\approx 0\\), \\(W_{\\text{post}} \\approx W\\),\\(V_{\\text{post}} \\approx V\\), as few salmon are harvested.\nIf \\(W \\gg 5\\), \\(\\alpha\\) is negative and large, \\(\\Phi(\\alpha) \\approx 0\\), harvesting dominates, but \\(W_{\\text{post}}\\) and \\(V_{\\text{post}}\\) stabilize to values reflecting the truncated distribution.\n\nNumerical Stability: Ensure \\(V &gt; 0\\) to avoid division by zero in \\(\\alpha\\). In practice, \\(V_{\\text{post}}\\) is always positive but smaller than (V).",
    "crumbs": [
      "Projects",
      "Salmon farming model"
    ]
  },
  {
    "objectID": "projects/portfolio/salmon/salmon_model.html",
    "href": "projects/portfolio/salmon/salmon_model.html",
    "title": "Nicol&oacute; Foppa Pedretti",
    "section": "",
    "text": "\\[\\begin{array}{l}\n\\frac{dN}{dt} = -(\\mu + h_r)N \\\\\n\\frac{dW}{dt} = g_r\\left(1 - \\frac{W}{W_{max}} \\right) - h_r(W-W_{post}) \\\\\n\\frac{dV}{dt} = \\sigma^2_gg_r - h_r(V-V_{post}) \\\\\n\\end{array}\\]\nHarvesting removes salmon with \\(w \\geq 5\\), calculated using the cumulative distribution function (CDF) of the normal distribution: \\[\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int^{z}_{-\\infty} e^{\\frac{-u^2}{2}}du\\]\n\\[P(w \\geq 5) = 1 - \\Phi \\left( \\frac{5-W}{\\sqrt{V}} \\right) \\qquad \\overset{\\text{harvested rate}}{\\longrightarrow} \\qquad h_r = h \\left[ 1 - \\Phi \\left( \\frac{5-W}{\\sqrt{V}} \\right) \\right]\\]\nTruncated Gaussian Distribution For a Gaussian random variable \\(w \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), truncated to \\(w &lt; a\\), the probability density function of the truncated distribution is:\n\\[f(w|w &lt; a) = \\frac{\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(w-\\mu)^2}{2\\sigma^2} \\right) }{\\Phi \\left( \\frac{a-\\mu}{\\sigma} \\right)} \\quad \\text{for } w &lt; a\\]\nwhere \\(\\Phi(z)\\) is the standard normal CDF, and the denominator \\(\\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right) = P(w &lt; a)\\) is the probability of \\(w &lt; a\\). In our case:\n\n\\(\\mu = W(t)\\): Mean weight before harvesting.\n\\(\\sigma^2 = V(t)\\): Variance before harvesting.\n\\(a=5\\): Truncation point (harvest salmon with \\(w \\geq 5\\)).\n\nLet’s define:\n\n\\(\\alpha = \\frac{a - \\mu}{\\sigma} = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\): Standardized truncation point.\n\\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)\\): Standard normal PDF.\n\\(\\Phi(\\alpha) = P(z &lt; \\alpha)\\): CDF at \\(\\alpha\\).\n\nThe fraction of salmon remaining after harvesting is \\(\\Phi(\\alpha)\\), and the fraction harvested is \\(1 - \\Phi(\\alpha)\\).\n\nConditional Mean (\\(W_{\\text{post}}\\))\nThe mean of a Gaussian distribution truncated at \\(w &lt; a\\) is:\n\\[\\mathbb{E}[w|w&lt;a] = \\mu - \\sigma \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}\\]\nSubstituting \\(\\mu = W(t)\\), \\(\\sigma = \\sqrt{V(t)}\\),\\(a = 5\\):\n\\[W_{\\text{post}} = W(t) - \\sqrt{V(t)} \\frac{\\phi \\left( \\frac{5-W(t)}{\\sqrt{V(t)}}\\right)}{\\Phi \\left( \\frac{5-W(t)}{\\sqrt{V(t)}}\\right)}\\]\nSimplify with \\(\\alpha = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\):\n\\[W_{\\text{post}} = W(t) - \\sqrt{V(t)} \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\]\nwhere:\n\n\\(\\phi(\\alpha) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\alpha^2}{2}\\right)\\)\n\\(\\Phi(\\alpha) = \\int_{-\\infty}^{\\alpha} \\phi(z) \\, dz\\)\n\nThe term \\(\\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\) is the hazard function (or inverse Mills ratio) for the standard normal, which adjusts the mean downward since larger weights are removed.\n\n\nConditional Variance (\\(V_{\\text{post}}\\))\nThe variance of the truncated Gaussian \\(w &lt; a\\) is:\n\\[Var[w|w&lt;a] = \\sigma^2 \\left[ 1 - \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)  \\frac{a-\\mu}{\\sigma}}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)} - \\left( \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}{\\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)} \\right)^2 \\right]\\]\nSubstituting \\(\\sigma^2 = V(t)\\), \\(\\mu = W(t)\\), \\(a=5\\), and \\(\\alpha = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\):\n\\[V_{\\text{post}} = V(t) \\left[ 1 - \\frac{\\phi(\\alpha) \\alpha}{\\Phi(\\alpha)} - \\left( \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)} \\right)^2 \\right]\\]\nThis expression accounts for the reduced variance after removing the upper tail of the distribution.\nNotes Simplification: Let \\(\\alpha = \\frac{5 - W}{\\sqrt{V}}\\). Then:\n\n\\(W_{\\text{post}} = W - \\sqrt{V} \\cdot \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)}\\)\n\\(V_{\\text{post}} = V \\left[ 1 - \\frac{\\phi(\\alpha) \\cdot \\alpha}{\\Phi(\\alpha)} - \\left( \\frac{\\phi(\\alpha)}{\\Phi(\\alpha)} \\right)^2 \\right]\\)\n\nBehavior:\n\nIf \\(W \\ll 5\\), \\(\\alpha\\) is large, \\(\\Phi(\\alpha) \\approx 1\\), \\(\\phi(\\alpha) \\approx 0\\), \\(W_{\\text{post}} \\approx W\\),\\(V_{\\text{post}} \\approx V\\), as few salmon are harvested.\nIf \\(W \\gg 5\\), \\(\\alpha\\) is negative and large, \\(\\Phi(\\alpha) \\approx 0\\), harvesting dominates, but \\(W_{\\text{post}}\\) and \\(V_{\\text{post}}\\) stabilize to values reflecting the truncated distribution.\n\nNumerical Stability: Ensure \\(V &gt; 0\\) to avoid division by zero in \\(\\alpha\\). In practice, \\(V_{\\text{post}}\\) is always positive but smaller than (V).\nWe want to model even the mean and standard deviation of the harvested fish:\n\\[f(w|w \\geq a) = \\frac{\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(w-\\mu)^2}{2\\sigma^2} \\right) }{1 - \\Phi \\left( \\frac{a-\\mu}{\\sigma} \\right)} \\quad \\text{for } w \\geq a\\]\nWe compute the mean of the truncated distribution:\n\\[\\mathbb{E}[w|w \\geq a] = \\mu + \\sigma \\frac{\\phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}{1 - \\Phi \\left( \\frac{a-\\mu}{\\sigma}\\right)}\\]\nIn our case:\n\n\\(\\mu = W(t)\\): Mean weight before harvesting.\n\\(\\sigma = \\sqrt{V(t)}\\): Standard deviation of weight.\n\\(a = 5\\): Harvesting threshold.\n\nDefine: \\(\\alpha = \\frac{a - \\mu}{\\sigma} = \\frac{5 - W(t)}{\\sqrt{V(t)}}\\) The mean weight of harvested salmon (W_{}) is:\n\\[W_{\\text{harvested}} = W(t) + \\sqrt{V(t)} \\cdot \\frac{\\phi\\left(\\frac{5 - W(t)}{\\sqrt{V(t)}}\\right)}{1 - \\Phi\\left(\\frac{5 - W(t)}{\\sqrt{V(t)}}\\right)}\\]\nUsing \\(\\alpha\\):\n\\[W_{\\text{harvested}} = W(t) + \\sqrt{V(t)} \\cdot \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\]"
  }
]